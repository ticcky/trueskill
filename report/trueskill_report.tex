\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[margin=0.5in]{geometry}
\usepackage{hyperref}
\title{Inference in TrueSkill}
\date{30.5.2013}
\author{Lukáš Žilka (lukas@zilka.me)}



\begin{document}

% SOME MACROS

% normal distribution macro \Normal
\newcommand{\Normal}[0]{\mathcal{N}}
\newcommand{\dx}[1]{\mathrm{d}#1}

% typesetting column vectors
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{bmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{bmatrix}
        \fi
}

\maketitle


\section{Introduction}

\section{Model}

\section{Inference}

\section{Take-home Message}

Gaussians rule! They are very powerful because you just need 2 parameters to represent the whole distribution, and consequentially you just update these two parameters when you need to update the distribution. For example, when you multiply/divide two Gausssians, the result is also a Gaussian:

\begin{itemize}
  \item Product of two Gaussian distributions over the same variable is a Gaussian distribution.
    \begin{equation}
      \Normal(x; \mu_1, \sigma_1^2) \cdot \Normal(x; \mu_2, \sigma_2^2) = \Normal(x; \mu, \sigma^2)
    \end{equation}

  \item Product of two Gaussian distributions over different variables is a multinomial Gaussian distribution with symmetric covariance matrix:

  \begin{equation}
      \Normal(x; \mu_1, \sigma_1^2) \cdot \Normal(y; \mu_2, \sigma_2^2) = \Normal(\colvec{2}{x}{y}; \colvec{2}{\mu_1}{\mu_2}, \begin{bmatrix} \sigma_1^2 & 0 \\ 0 & \sigma_2^2 \\ \end{bmatrix})
    \end{equation}

  \item If two random variables are from Gaussians, the sum of those variables is also a Gaussian.
    \begin{align}
        X     & \sim \Normal(x; \mu_1, \sigma_1^2) \\
        Y     & \sim \Normal(x; \mu_2, \sigma_2^2) \\
        X + Y & \sim \Normal(x; \mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2) \\
    \end{align}

  \item Sum of two Gaussian distributions is NOT a Gaussian.
    \begin{align}
      \Normal(x; \mu_1, \sigma_1) + \Normal(x; \mu_2, \sigma_2) \not= \Normal(x; \cdot)
    \end{align}

  \item Integration of two Gaussian that are over different variables, where one ot them is the mean parameter for the other, can be turned into a convolution, and the result is again a Gaussian. Convolution is an integral of the form $\int f(t-x)g(x)\dx{t}$.
    \begin{align}
      p(x) = \int \Normal(x; \mu_0, \sigma^2_0) \Normal(y; x, \sigma^2) \dx{x} =
    \end{align}
    Following the equation for the Gaussian distribution, we can take out the x from the mean of the second Gaussian and put it to its argument.
    \begin{align}
      = \int \Normal(x; \mu_0, \sigma^2_0) \Normal(y - x; 0, \sigma^2) \dx{x} \\
    \end{align}
    Now the form somehow resembles the form of convolution given above: $\int f(x) g(y - x)\dx{x}$, and consequentially, we can use the result for Gaussian convolution. Its derivation can be found in~\cite{math_behind_trueskill}.
    \begin{align}
      = \Normal(x; \mu_0, \sigma^2_0 + \sigma^2) \\
    \end{align}
\end{itemize}

\section{References}
\bibliographystyle{apalike}
\bibliography{mybib}

\end{document}